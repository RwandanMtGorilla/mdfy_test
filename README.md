- [文档预处理之 文本化](#文档预处理之-文本化)
  - [结构化信息提取 重要性](#结构化信息提取-重要性)
  - [评价标准](#评价标准)
  - [测评](#测评)
    - [基于大模型的识别方案举例](#基于大模型的识别方案举例)
      - [测试](#测试)
      - [小结](#小结)
    - [基于本地OCR的识别方案举例](#基于本地ocr的识别方案举例)
      - [测试](#测试-1)
      - [小结](#小结-1)
    - [基于云端OCR的识别方案举例](#基于云端ocr的识别方案举例)
      - [测试](#测试-2)
      - [小结](#小结-2)
  - [大结论](#大结论)
- [参考文献](#参考文献)


## 文档预处理之 文本化
浅析结构化信息提取技术，技术选型及一些个人测试

### 结构化信息提取 重要性

有人比喻“数据”是大模型时代的石油，这话不假。在实际生产过程中，不论是知识图谱构建还是RAG检索，都需要用到大量的文本数据。但现如今，大量历史档案、法律文件及商业材料依然以扫描件、图像或半结构化格式存储，给信息提取、内容理解及智能检索带来了诸多技术难题。

在这样的背景下，结构化信息提取重要性不言而喻。网络上也涌现出了各式各样的结构化信息提取方法。对于开发者而言，结构化信息提取的“落地”与“可用性”才是真正的考验。研究论文中令人惊叹的指标、理论上的高精度模型，在现实生产环境中可能面临性能瓶颈、成本过高、部署难度大等诸多挑战。

本文将围绕结构化信息提取技术展开分析，立足实际应用需求，聚焦当前主流工具和方法的选型，结合一系列个人测试与实践经验，深入探讨其在不同场景下的表现、优势与不足。从技术指标到生产可行性，我们将为开发者提供一份实用的参考指南，帮助大家在纷繁的技术选型中找到最适合的落地方案，真正让技术服务于业务，释放数据的潜在价值。


### 评价标准

首先作为测评，首先定一下标准，设定目标输出格式为markdown。

markdown 作为一种 *增强的文本格式* 相较纯文本而言，为数据保有了其中固有的结构（表格，标题，列表等）。同时作为大模型原生支持的文本格式，使用markdown格式输入也能让输出效果更好。

关于测试上的结果要求，首先最重要的是，结果可用。我们定了三个正确性指标：其中，文本准确性，是所有文本解析的基础，有研究[0](https://arxiv.org/abs/2412.02592v1)指出，正确性将显著影响RAG的效果；表格准确性则为一个准确性难点，尤其是有多个单元格合并的情况下，很难识别准确；标题正确性主要考察标题文本的标题层级是否正确。其次需要考虑识别速度，成本等问题。考虑到有些组织内信息不能上传外网，添加了隐私性，即能否本地部署这一指标。最后考虑到有些方法路径尚不成熟，部署复杂度大，因此能否便捷使用也是需要考虑的点。最终得到的评价表格如下: 

评价表格:*
| 名称 | 访问地址 | 文本正确性 | 表格正确性 | 标题正确性 | 识别速度 | 成本 | 本地部署 | 便捷使用 |
| ---- | ------- | --------- | --------- | --------- | ------- | ---- | ------- | ------- |


* 由于参与后处理的是LLM 所以关于文本识别准确有一定容错 
如果需要关于正确性的量化评价，可以采用[Markdown Tester](https://github.com/intsig-textin/markdown_tester)


### 测评

使用的待测试pdf:
随机选取的一份上交所上市公司的2023年年报 全文193页。

![alt text](<images/屏幕截图 2024-12-24 000545.png>) ![alt text](<images/屏幕截图 2024-12-24 000646.png>) ![alt text](<images/屏幕截图 2024-12-24 000752.png>)

金融年报是电子文档中相对复杂的一类，文字密度大，表格复杂度高，标题层级多，对模型能力有较大考验。遂选取之作为测试素材。


#### 基于大模型的识别方案举例

市面上流行的几个开源pdf转markdown方法，大体可以分为两种，一类走传统版面分析+公式表格识别+OCR方案，另一类则是走视觉大模型路线。

利用大模型执行pdf转markdown算是一种逻辑上比较容易的办法，其借助大模型本身强大的视觉识别能力，进行力大砖飞的转换。

从原理上，这种方法可以自如地进行转换，同时可以在转换过程中保留尽可能多的视觉信息，基础的诸如标题层级，进阶的还可以对图片进行一定的语义解释。

在宣传上效果也是相当的好，视觉大模型的接口也容易获得，有条件的情况下也可以本地部署。

本次实验采取 识别能力靠前[1]，且常用的gpt-4o模型 配合 [gptpdf](https://github.com/CosmosShadow/gptpdf) 来进行实验：

##### 测试 
gptpdf的封装度较高，且依赖较少，一次pip即可安装。

如果是使用openai服务的话，只需填写上自己的key即可。如果自己有大模型部署的话，也可改成自己的代理地址也可使用本地的视觉模型。

测试代码用的是单线程，由于速度较慢远低于预期，遂只拆出前30页进行测试。效果如下：

可以看到，问题还是比较多的：
比如幻觉问题：
 ![alt text](<images/屏幕截图 2025-01-13 112711.png>) 大模型幻觉出了一些奇怪的标题。

识别结构不稳定：
![alt text](<images/屏幕截图 2024-12-24 000753.png>) 此处本应是一个表格。

我使用的是gptpdf默认的prompt，可能有优化空间。但是效果的确不尽如人意。

而且速度也是有够慢，仅仅三十页运行了477.34s，就算可以多线程，单页16s的开销也使其很难用于快速文档解析场景。

##### 小结

| 名称 | 访问地址 | 文本正确性 | 表格正确性 | 标题正确性 | 识别速度 | 成本 | 本地部署 | 便捷使用 |
| ---- | ------- | --------- | --------- | --------- | ------- | ---- | ------- | ------- |
|gptpdf|https://github.com/CosmosShadow/gptpdf|文本正确性: 偶有差错|表格正确性: 语义正确 格式错误|标题正确性: 基本无误|成本: 本地算力/gpt4o 约 0.112￥/页(含读取和输出)|本地部署：可行(基于视觉大模型，显存要求高)|可行|便捷使用：部署便捷|


本次测试还有一些可以优化的点，例如使用经过调试的提示词，或者换用对中文视觉支持更好的大模型。但该方案整体上价格偏高，单管道处理速度也较慢，除非和一些基于大模型的预处理进行步骤合并，否则不推荐使用。

#### 基于本地OCR的识别方案举例
相对视觉大模型方案，OCR方案则小巧且复杂，其使用较小的模型各司其职，并对结果进行拼接。其算力要求相对低的特点也使其适用于本地部署，一个广受好评的解决方案是[MinerU](https://github.com/opendatalab/MinerU)，作为开源的数据提取工具，截止稿成，其在github上已经有24.3k stars.

##### 测试
minerU的安装相对复杂些，且如果要安装gpu版本需要额外的步骤。
该方案是完全开源的，好消息是有些组件可以根据需求定制化更改。坏消息是，可能有一些bug，需要查issues自行修复。

其速度还算过关，在i7-2700+3090上运行，平均4.52s每页。其在不同阶段使用的算力硬件也不同，多线程情况下速度或许会更快。

值得注意的是，由于markdown格式表格不易于显示复杂表，minerU的默认表格识别将会把表格转换为html格式，从纯文本打开的话会像是这样:
![alt text](<images/屏幕截图 2025-01-13 143935.png>)
issues中有人给出了能转换为markdown格式的替代方案，但是这同样需要额外的配置，在此暂不讨论。

来看看效果：
![alt text](<images/屏幕截图 2025-01-13 144657.png>) 标题只有一层，即`是标题`/`不是标题`。
在表格识别能力上偏弱：
偶尔会出现例如：
![alt text](<images/屏幕截图 2025-01-13 144900.png>) 无限复读机；

![alt text](<images/屏幕截图 2025-01-13 145247.png>) 换页时文本错误/表格结构错误。
##### 小结

| 名称 | 访问地址 | 文本正确性 | 表格正确性 | 标题正确性 | 识别速度 | 成本 | 本地部署 | 便捷使用 |
| MinerU | https://github.com/opendatalab/MinerU | 基本正确 | 较差 | 只能简单区分是否为标题 且识别准确性不高 | 正相关于硬件算力(i7-2700+3090上 4.52s/页) | 本地部署(硬件折旧+电力损耗) | 可本地部署 | 不甚便捷 |

大概是开源领域最好的ocr方案了，如果有本地算力且文件保密要求高的话还是比较推荐的。默认的html格式个人认为有些鸡肋，其不能保证准确性，同时也不利于大模型读取。先前提到的转换为markdown格式的替代方案我也尝试过，能一定程度减少识别错误，但会增加使用难度，且还是有较多错误。

#### 基于云端OCR的识别方案举例
如果项目没有本地部署需求，那么云端OCR是个好方案，其价格相对大模型方法低廉许多，且响应速度快。横评了一众中文OCR方案，[Textin](https://www.textin.com/document/pdf_to_markdown)的数据是最好的。

##### 测试
速度奇快，一份193页的pdf文件仅消耗了13s，几乎是其余方案的百倍。

几乎没有错误，只是偶有标题会被漏标：
![alt text](<images/屏幕截图 2025-01-13 161708.png>)
只有极复杂的表格才能使其产生小错误：
原表格：![alt text](<images/屏幕截图 2025-01-13 162145.png>)
识别后：![alt text](<images/屏幕截图 2025-01-13 162254.png>)


##### 小结

| 名称 | 访问地址 | 文本正确性 | 表格正确性 | 标题正确性 | 识别速度 | 成本 | 本地部署 | 便捷使用 |
| ---- | ------- | --------- | --------- | --------- | ------- | ---- | ------- | ------- |
| TextIn | https://www.textin.com/document/pdf_to_markdown | 基本正确 |基本正确 | 层级支持，偶有错误 | 极快，平均0.07s/页 | 0.05￥/页 | 尚未发布 | 非常便捷 |

综合下来是速度且效果最好的OCR方案了，适用大多数场景，非常推荐。

### 大结论

总表：

| 名称 | 访问地址 | 文本正确性 | 表格正确性 | 标题正确性 | 识别速度 | 成本 | 本地部署 | 便捷使用 |
| ---- | ------- | --------- | --------- | --------- | ------- | ---- | ------- | ------- |
|gptpdf|https://github.com/CosmosShadow/gptpdf|文本正确性: 偶有差错|表格正确性: 语义正确 格式错误|标题正确性: 基本无误|成本: 本地算力/gpt4o 约 0.112￥/页(含读取和输出)|本地部署：可行(基于视觉大模型，显存要求高)|可行|便捷使用：部署便捷|
| MinerU | https://github.com/opendatalab/MinerU | 基本正确 | 较差 | 只能简单区分是否为标题 且识别准确性不高 | 正相关于硬件算力(i7-2700+3090上 4.52s/页) | 本地部署(硬件折旧+电力损耗) | 可本地部署 | 不甚便捷 |
| TextIn | https://www.textin.com/document/pdf_to_markdown | 基本正确 |基本正确 | 层级支持，偶有错误 | 极快，平均0.07s/页 | 0.05￥/页 | 尚未发布 | 非常便捷 |

从效果上，几种方法都在可接受的范围内，

视觉大模型方案成本高昂且可靠性较差，尽管近来有较多类似功能的开源仓库，但其效果较差，价格高，速度慢，因此不建议使用此类方案。

从部署成本来说，如果有较强的本地算力且用量较大，建议使用本地OCR识别方案；如果对精确度要求高，资金充足。则建议使用云端OCR的识别方案。

最后附上测试代码和结果，也可以帮助你便捷完成批量转换。
[mdfy_test](https://github.com/RwandanMtGorilla/mdfy_test)

## 参考文献
0. OCR Hinders RAG: Evaluating the Cascading Impact of OCR on Retrieval-Augmented Generation https://arxiv.org/abs/2412.02592v1
1. llm的 基础OCR识字能力 CC-OCR: A Comprehensive and Challenging OCR Benchmark for Evaluating Large Multimodal Models in Literacy https://arxiv.org/pdf/2412.02210
2. Document Parsing Unveiled: Techniques, Challenges,and Prospects for Structured Information Extraction 文档解析综述 https://arxiv.org/pdf/2410.21169 
3. A Comparative Study of PDF Parsing Tools Across Diverse Document Categories  https://arxiv.org/pdf/2410.09871
